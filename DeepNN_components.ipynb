{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c61b664e",
      "metadata": {
        "id": "c61b664e"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ce85786",
      "metadata": {
        "id": "7ce85786"
      },
      "source": [
        "### Weight initializers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc3ffbe6",
      "metadata": {
        "id": "bc3ffbe6"
      },
      "outputs": [],
      "source": [
        "class RandomInitializer():\n",
        "    def initialize(self, shape):\n",
        "        W = np.random.randn(shape[0], shape[1])\n",
        "        return W\n",
        "\n",
        "class ZerosInitializer():\n",
        "    def initialize(self, shape):\n",
        "        W = np.zeros(shape)\n",
        "        return W\n",
        "\n",
        "class HeInitializer():\n",
        "    def initialize(self, shape):\n",
        "        W = np.random.randn(shape[0], shape[1]) * np.sqrt(2 / shape[1])\n",
        "        return W\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b47a59c",
      "metadata": {
        "id": "9b47a59c"
      },
      "source": [
        "## Activation funcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98f5e669",
      "metadata": {
        "id": "98f5e669"
      },
      "outputs": [],
      "source": [
        "class RELU():\n",
        "    def activate(self, Z):\n",
        "        return Z * (Z > 0)\n",
        "\n",
        "    def derivative(self, Z):\n",
        "        return 1 * (Z > 0)\n",
        "\n",
        "\n",
        "class Sigmoid():\n",
        "    def activate(self, Z):\n",
        "        return 1 / (1 + np.exp(-Z))\n",
        "\n",
        "    def derivative(self, Z):\n",
        "        return self.activate(Z) * (1 - self.activate(Z))\n",
        "\n",
        "\n",
        "class Linear():\n",
        "    def activate(self, Z):\n",
        "        return Z\n",
        "\n",
        "    def derivative(self, Z):\n",
        "        return (np.ones(Z.shape))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaafefba",
      "metadata": {
        "id": "aaafefba"
      },
      "source": [
        "## Costs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d40d62",
      "metadata": {
        "id": "b5d40d62"
      },
      "outputs": [],
      "source": [
        "class BinaryCrossEntropy():\n",
        "    def compute_cost(self, y_pred, y_true):\n",
        "        #shape y_pred and y_true = (1, m_examples)\n",
        "        m = y_true.shape[1]\n",
        "\n",
        "        #lets cut off a  tiny constant to avoid log0 problem\n",
        "        epsilon = 10 ** -15\n",
        "        y_pred = np.clip(y_pred, epsilon, 1-epsilon)\n",
        "\n",
        "        cost =  -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "        cost = np.sum(cost, axis=1, keepdims=True) * (1 / m)\n",
        "\n",
        "        return (cost)\n",
        "\n",
        "    def derivative(self, y_pred, y_true):\n",
        "\n",
        "        #Do it to avoid division by 0\n",
        "        epsilon = 10 ** -15\n",
        "        y_pred = np.clip(y_pred, epsilon, 1-epsilon)\n",
        "\n",
        "        dA = - (y_true / y_pred) + (1 - y_true) / (1 - y_pred)\n",
        "\n",
        "        return (dA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0793ce8",
      "metadata": {
        "id": "b0793ce8"
      },
      "source": [
        "## Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b47dcaf",
      "metadata": {
        "id": "8b47dcaf"
      },
      "outputs": [],
      "source": [
        "class Layer():\n",
        "    def __init__(self, n_units, activation, l2_reg=0, weight_initializer=HeInitializer):\n",
        "        self.activation = activation\n",
        "        self.n_units = n_units\n",
        "        self.l2_reg =l2_reg\n",
        "\n",
        "        self.activation = activation()\n",
        "\n",
        "        #initialize cache\n",
        "        self.Z = None\n",
        "        self.A = None\n",
        "\n",
        "        #initialize params\n",
        "        #waiting for initializing the model\n",
        "        self.initializer = weight_initializer\n",
        "        self.W = None\n",
        "        self.b = ZerosInitializer().initialize((n_units, 1))\n",
        "\n",
        "        #We will need them for Adam and Momentum\n",
        "        #moments\n",
        "        self.V_dW = None\n",
        "        self.V_db = ZerosInitializer().initialize((n_units, 1))\n",
        "        #RMS_prop part\n",
        "        self.S_dw = None\n",
        "        self.S_db = ZerosInitializer().initialize((n_units, 1))\n",
        "\n",
        "\n",
        "        #grads\n",
        "        self.dZ = None\n",
        "        self.dA = None\n",
        "\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def initialize(self, n_units_prev):\n",
        "        shape = (self.n_units, n_units_prev)\n",
        "        self.W = self.initializer().initialize(shape)\n",
        "\n",
        "        #initialize params in case we use Adam/Momentum\n",
        "        self.V_dW = ZerosInitializer().initialize(shape)\n",
        "        self.S_dW = ZerosInitializer().initialize(shape)\n",
        "\n",
        "\n",
        "    def forward_propogation(self, A_prev):\n",
        "        #keep A_prev for backprop\n",
        "        self.A_prev = A_prev\n",
        "\n",
        "        self.Z = np.dot(self.W, A_prev) + self.b\n",
        "        self.A = self.activation.activate(self.Z)\n",
        "\n",
        "        return (self.A)\n",
        "\n",
        "    def back_propogation(self, W_next=None, dZ_next=None, dA_final=None):\n",
        "\n",
        "        batch_size = self.Z.shape[1]\n",
        "\n",
        "        #Check for valid input\n",
        "        if dA_final is None:\n",
        "            if W_next is None or dZ_next is None:\n",
        "                raise ValueError(\"Either both W_next and dZ_next must be provided, or dA_final must be provided.\")\n",
        "\n",
        "\n",
        "        #compute and keep gradients\n",
        "        #dA_final is a specific case, where our layer is final and we compute cost derivs\n",
        "        if dA_final is not None:\n",
        "            self.dA = dA_final\n",
        "        else:\n",
        "            self.dA = np.dot(W_next.T, dZ_next)\n",
        "\n",
        "        self.dZ = self.dA * self.activation.derivative(self.Z)\n",
        "\n",
        "        #regularization\n",
        "        l2_term = (self.l2_reg / batch_size) * self.W\n",
        "\n",
        "        self.dW = np.dot(self.dZ, self.A_prev.T) * (1 / batch_size) + l2_term\n",
        "        self.db = np.sum(self.dZ, axis=1, keepdims=True) * (1 / batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67fa11ee",
      "metadata": {
        "id": "67fa11ee"
      },
      "source": [
        "## Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b330b013",
      "metadata": {
        "id": "b330b013"
      },
      "outputs": [],
      "source": [
        "class GradientDescent():\n",
        "    def __init__(self, learning_rate):\n",
        "        self.counter = 1\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def update(self, layer):\n",
        "        #update params of layer\n",
        "        layer.W = layer.W - self.learning_rate * layer.dW\n",
        "        layer.b = layer.b - self.learning_rate * layer.db\n",
        "\n",
        "    def tick(self):\n",
        "        self.counter += 1\n",
        "\n",
        "\n",
        "class Momentum():\n",
        "    def __init__(self, learning_rate, beta=0.9, bias_correction=False):\n",
        "\n",
        "        self.counter = 1\n",
        "        self.learning_rate = learning_rate\n",
        "        self.beta = beta\n",
        "\n",
        "        self.bias_correction = bias_correction\n",
        "        self.epsilon = 10 ** -8\n",
        "\n",
        "    def update(self, layer):\n",
        "\n",
        "        #compute new velocities\n",
        "        layer.V_dW = self.beta * layer.V_dW + (1 - self.beta) * layer.dW\n",
        "        layer.V_db = self.beta * layer.V_db + (1 - self.beta) * layer.db\n",
        "\n",
        "        if self.bias_correction:\n",
        "            #correct velocities\n",
        "            layer.V_dW = layer.V_dW / (1 - self.beta ** self.counter)\n",
        "            layer.V_db = layer.V_db / (1 - self.beta ** self.counter)\n",
        "\n",
        "\n",
        "        #update params\n",
        "        layer.W = layer.W - self.learning_rate * layer.V_dW\n",
        "        layer.b = layer.b - self.learning_rate * layer.V_db\n",
        "\n",
        "    def tick(self):\n",
        "        self.counter += 1\n",
        "\n",
        "\n",
        "class Adam():\n",
        "    def __init__(self, alpha, beta1=0.9, beta2=0.99, bias_correction=False):\n",
        "\n",
        "        self.counter = 1\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.beta1 = beta1 #Momentum\n",
        "        self.beta2 = beta2 #RMSprop\n",
        "\n",
        "        self.bias_correction = bias_correction\n",
        "\n",
        "        self.epsilon = 10 ** -8\n",
        "\n",
        "    def update(self, layer):\n",
        "        #compute new velocities\n",
        "        layer.V_dW = self.beta1 * layer.V_dW + (1 - self.beta1) * layer.dW\n",
        "        layer.V_db = self.beta1 * layer.V_db + (1 - self.beta1) * layer.db\n",
        "\n",
        "        #compute new second moments\n",
        "        layer.S_dW = self.beta2 * layer.S_dW + (1 - self.beta2) * np.square(layer.dW)\n",
        "        layer.S_db = self.beta2 * layer.S_db + (1 - self.beta2) * np.square(layer.db)\n",
        "\n",
        "\n",
        "        if self.bias_correction:\n",
        "            #correct velocities\n",
        "            layer.V_dW = layer.V_dW / (1 - self.beta1 ** self.counter)\n",
        "            layer.V_db = layer.V_db / (1 - self.beta1 ** self.counter)\n",
        "\n",
        "            #correct 2nd moments\n",
        "            layer.S_dW = layer.S_dW / (1 - self.beta2 ** self.counter)\n",
        "            layer.S_db = layer.S_db / (1 - self.beta2 ** self.counter)\n",
        "\n",
        "        #UPdate parameters\n",
        "\n",
        "        layer.W = layer.W - self.alpha * (layer.V_dW / (np.sqrt(layer.S_dW) + self.epsilon))\n",
        "        layer.b = layer.b - self.alpha * (layer.V_db / (np.sqrt(layer.S_db) + self.epsilon))\n",
        "\n",
        "    def tick(self):\n",
        "        self.counter += 1\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model():\n",
        "  def __init__(self, X, Y,layers):\n",
        "    #X has shape (n_features, m_examples)\n",
        "    #Y has shape (1, m_examples)\n",
        "\n",
        "    self.layers = layers\n",
        "    self.n_layers = len(layers)\n",
        "\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "\n",
        "    self.minibatches = [] #list of tuples (X_batch, Y_batch)\n",
        "\n",
        "    self.costfunc = None\n",
        "    self.optimizer = None\n",
        "\n",
        "  def _init_weights(self):\n",
        "\n",
        "    n_unit_prev = self.X.shape[0]\n",
        "\n",
        "    for layer in self.layers:\n",
        "      layer.initialize(n_unit_prev)\n",
        "\n",
        "      #set n_units_prev for next initialization\n",
        "      n_unit_prev = layer.n_units\n",
        "\n",
        "  def _make_minibatches(self, batch_size=None):\n",
        "    if batch_size is None:\n",
        "      self.minibatches.append((self.X, self.Y))\n",
        "\n",
        "    #TODO: implement splitting into minibatches here...\n",
        "\n",
        "  def compile(self, costfunc, optimizer):\n",
        "    self.costfunc = costfunc\n",
        "    self.optimizer = optimizer\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    A_prev = X\n",
        "\n",
        "    for layer in self.layers:\n",
        "      A = layer.forward_propogation(A_prev)\n",
        "      A_prev = A\n",
        "\n",
        "    return A\n",
        "\n",
        "  def _backprop(self, dA_final):\n",
        "\n",
        "      L = self.n_layers\n",
        "\n",
        "      #mannualy set backprop for last layer\n",
        "      self.layers[L - 1].back_propogation(dA_final=dA_final)\n",
        "\n",
        "      #loop goes from L - 2 up to 0\n",
        "      for l in range(L - 2, -1, -1):\n",
        "        self.layers[l].back_propogation(self.layers[l + 1].W,\n",
        "                                        self.layers[l + 1].dZ)\n",
        "\n",
        "  def _update_all_params(self):\n",
        "    #goes over layers updating params using computed gradients\n",
        "    for layer in self.layers:\n",
        "      self.optimizer.update(layer)\n",
        "\n",
        "    self.optimizer.tick()\n",
        "\n",
        "\n",
        "  def fit(self, epochs, batch_size=None):\n",
        "\n",
        "    #init weights\n",
        "    self._init_weights()\n",
        "\n",
        "    #split into minibatches\n",
        "    self._make_minibatches(batch_size)\n",
        "\n",
        "\n",
        "    history = []\n",
        "    for epoch in range(1, epochs + 1):\n",
        "\n",
        "      #compute cost\n",
        "      all_predictions = self.predict(self.X)\n",
        "      total_cost = self.costfunc.compute_cost(all_predictions, self.Y)\n",
        "      print(\"Epoch #{}, cost = {}\".format(epoch, total_cost))\n",
        "\n",
        "\n",
        "      for batch in self.minibatches:\n",
        "        X_batch, Y_batch = batch\n",
        "\n",
        "        batch_predictions = self.predict(X_batch)\n",
        "\n",
        "        dA_final = self.costfunc.derivative(batch_predictions, Y_batch)\n",
        "\n",
        "        self._backprop(dA_final)\n",
        "        self._update_all_params()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M2mkGxe_mA5r"
      },
      "id": "M2mkGxe_mA5r",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "4dd48984",
      "metadata": {
        "id": "4dd48984"
      },
      "outputs": [],
      "source": [
        "l1 = Layer(3, activation=Sigmoid)\n",
        "\n",
        "\n",
        "X = np.array([[3, 4],\n",
        "              [0, 3],\n",
        "               [2, 4],\n",
        "               [0 , 0],\n",
        "                [3, 0]]).T\n",
        "\n",
        "y = np.array([[1, 0, 1, 0, 1]])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [\n",
        "       Layer(n_units=3, activation = RELU),\n",
        "       Layer(n_units=1, activation = Sigmoid)\n",
        "]\n",
        "\n",
        "model = Model(X, y, layers)\n",
        "\n",
        "model.compile(costfunc = BinaryCrossEntropy(),\n",
        "              optimizer = Adam(0.1))"
      ],
      "metadata": {
        "id": "ILNSMZGNvNpP"
      },
      "id": "ILNSMZGNvNpP",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(30)"
      ],
      "metadata": {
        "id": "8Ns5Oqgdv0yS",
        "outputId": "cde238a2-0d20-4add-a4a1-a4056a92b0dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8Ns5Oqgdv0yS",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #1, cost = [[2.59946848]]\n",
            "Epoch #2, cost = [[1.93706964]]\n",
            "Epoch #3, cost = [[1.23842055]]\n",
            "Epoch #4, cost = [[0.70244106]]\n",
            "Epoch #5, cost = [[0.50651027]]\n",
            "Epoch #6, cost = [[0.55708919]]\n",
            "Epoch #7, cost = [[0.61476996]]\n",
            "Epoch #8, cost = [[0.62907016]]\n",
            "Epoch #9, cost = [[0.60131499]]\n",
            "Epoch #10, cost = [[0.563903]]\n",
            "Epoch #11, cost = [[0.47974722]]\n",
            "Epoch #12, cost = [[0.41282704]]\n",
            "Epoch #13, cost = [[0.34181868]]\n",
            "Epoch #14, cost = [[0.29051136]]\n",
            "Epoch #15, cost = [[0.26282052]]\n",
            "Epoch #16, cost = [[0.23645504]]\n",
            "Epoch #17, cost = [[0.21179214]]\n",
            "Epoch #18, cost = [[0.18906917]]\n",
            "Epoch #19, cost = [[0.16840333]]\n",
            "Epoch #20, cost = [[0.14981368]]\n",
            "Epoch #21, cost = [[0.13324384]]\n",
            "Epoch #22, cost = [[0.11858368]]\n",
            "Epoch #23, cost = [[0.10568874]]\n",
            "Epoch #24, cost = [[0.09439627]]\n",
            "Epoch #25, cost = [[0.08453773]]\n",
            "Epoch #26, cost = [[0.07594779]]\n",
            "Epoch #27, cost = [[0.0684703]]\n",
            "Epoch #28, cost = [[0.0619618]]\n",
            "Epoch #29, cost = [[0.05629318]]\n",
            "Epoch #30, cost = [[0.05135004]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X)"
      ],
      "metadata": {
        "id": "dZ1P37jT7zeB",
        "outputId": "48a0ed66-3835-4097-e0e5-9d6b3a9cb0cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dZ1P37jT7zeB",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99999764, 0.11051053, 0.99905918, 0.11051053, 0.99999788]])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbff54c0",
      "metadata": {
        "id": "dbff54c0",
        "outputId": "ea9d5adf-8cde-4235-86d6-c850f1aa68ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0, cost = [[0.62000051]]\n",
            "i = 10, cost = [[0.57468473]]\n",
            "i = 20, cost = [[0.52557084]]\n",
            "i = 30, cost = [[0.46696421]]\n",
            "i = 40, cost = [[0.39693643]]\n",
            "i = 50, cost = [[0.31846955]]\n",
            "i = 60, cost = [[0.23861208]]\n",
            "i = 70, cost = [[0.17038884]]\n",
            "i = 80, cost = [[0.12540482]]\n",
            "i = 90, cost = [[0.10113414]]\n",
            "i = 100, cost = [[0.08754819]]\n"
          ]
        }
      ],
      "source": [
        "layer1 = Layer(n_units=3, activation = RELU)\n",
        "layer2 = Layer(1, Sigmoid)\n",
        "costf = BinaryCrossEntropy()\n",
        "\n",
        "layer1.initialize(2)\n",
        "layer2.initialize(3)\n",
        "\n",
        "\n",
        "\n",
        "alpha = 0.01\n",
        "epochs = 100\n",
        "\n",
        "optimizer = Adam(alpha)\n",
        "\n",
        "for i in range(epochs+1):\n",
        "    a1 = layer1.forward_propogation(X)\n",
        "    a2 = layer2.forward_propogation(a1)\n",
        "\n",
        "    cost = costf.compute_cost(a2, y)\n",
        "    if (i % (epochs//10) == 0):\n",
        "        print(\"i = {}, cost = {}\".format(i, cost))\n",
        "\n",
        "\n",
        "    dA_final = costf.derivative(a2, y)\n",
        "\n",
        "    #back_prop\n",
        "    layer2.back_propogation(dA_final=dA_final)\n",
        "    layer1.back_propogation(layer2.W, layer2.dZ)\n",
        "\n",
        "    #update params\n",
        "    optimizer.update(layer1)\n",
        "    optimizer.update(layer2)\n",
        "    optimizer.tick()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "154d51d7",
      "metadata": {
        "id": "154d51d7",
        "outputId": "f658d89f-2891-4c84-987a-aab48ef83416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99646007, 0.17372499, 0.96538687, 0.17372499, 0.98819461]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "a1 = layer1.forward_propogation(X)\n",
        "a2 = layer2.forward_propogation(a1)\n",
        "\n",
        "a2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a82e2fa",
      "metadata": {
        "id": "0a82e2fa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71158021",
      "metadata": {
        "id": "71158021",
        "outputId": "6eaee92f-f6d3-420c-d3ac-9f6c640372b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.2004948 , 0.41839818, 0.24593324]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "layer2.W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d520521b",
      "metadata": {
        "id": "d520521b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}