{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c61b664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce85786",
   "metadata": {},
   "source": [
    "### Weight initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc3ffbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomInitializer():        \n",
    "    def initialize(self, shape):\n",
    "        W = np.random.randn(shape[0], shape[1])\n",
    "        return W\n",
    "    \n",
    "class ZerosInitializer():\n",
    "    def initialize(self, shape):\n",
    "        W = np.zeros(shape)\n",
    "        return W\n",
    "\n",
    "class HeInitializer():\n",
    "    def initialize(self, shape):\n",
    "        W = np.random.randn(shape[0], shape[1]) * np.sqrt(2 / shape[1])\n",
    "        return W\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b47a59c",
   "metadata": {},
   "source": [
    "## Activation funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98f5e669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25      , 0.19661193, 0.00664806, 0.04124902]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RELU():\n",
    "    def activate(self, Z):\n",
    "        return Z * (Z > 0)\n",
    "    \n",
    "    def derivative(self, Z):\n",
    "        return 1 * (Z > 0)\n",
    "\n",
    "\n",
    "class Sigmoid():\n",
    "    def activate(self, Z):\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    def derivative(self, Z):\n",
    "        return self.activate(Z) * (1 - self.activate(Z))\n",
    "    \n",
    "\n",
    "class Linear():\n",
    "    def activate(self, Z):\n",
    "        return Z\n",
    "    \n",
    "    def derivative(self, Z):\n",
    "        return (np.ones(Z.shape))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaafefba",
   "metadata": {},
   "source": [
    "## Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b5d40d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCrossEntropy():\n",
    "    def compute_cost(self, y_pred, y_true):\n",
    "        #shape y_pred and y_true = (1, m_examples)\n",
    "        m = y_true.shape[1]\n",
    "        \n",
    "        #lets cut off a  tiny constant to avoid log0 problem\n",
    "        epsilon = 10 ** -15\n",
    "        y_pred = np.clip(y_pred, epsilon, 1-epsilon)\n",
    "        \n",
    "        cost =  -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "        \n",
    "        cost = np.sum(cost, axis=1, keepdims=True) * (1 / m)\n",
    "        \n",
    "        return (cost)\n",
    "    \n",
    "    def derivative(self, y_pred, y_true):\n",
    "        \n",
    "        #Do it to avoid division by 0\n",
    "        epsilon = 10 ** -15\n",
    "        y_pred = np.clip(y_pred, epsilon, 1-epsilon)\n",
    "        \n",
    "        dA = - (y_true / y_pred) + (1 - y_true) / (1 - y_pred)\n",
    "        \n",
    "        return (dA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0793ce8",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b47dcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    def __init__(self, n_units, activation, l2_reg=0, weight_initializer=HeInitializer):\n",
    "        self.activation = activation\n",
    "        self.n_units = n_units\n",
    "        self.l2_reg =l2_reg\n",
    "        \n",
    "        self.activation = activation()\n",
    "        \n",
    "        #initialize cache\n",
    "        self.Z = None\n",
    "        self.A = None\n",
    "        \n",
    "        #initialize params\n",
    "        #waiting for initializing the model\n",
    "        self.initializer = weight_initializer\n",
    "        self.W = None\n",
    "        self.b = ZerosInitializer().initialize((n_units, 1))\n",
    "        \n",
    "        #grads\n",
    "        self.dZ = None\n",
    "        self.dA = None\n",
    "        \n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "    def initialize(self, n_units_prev):\n",
    "        shape = (self.n_units, n_units_prev)\n",
    "        self.W = self.initializer().initialize(shape)\n",
    "        \n",
    "        \n",
    "    def forward_propogation(self, A_prev):\n",
    "        #keep A_prev for backprop\n",
    "        self.A_prev = A_prev\n",
    "        \n",
    "        self.Z = np.dot(self.W, A_prev) + self.b\n",
    "        self.A = self.activation.activate(self.Z)\n",
    "        \n",
    "        return (self.A)\n",
    "    \n",
    "    def back_propogation(self, W_next, dZ_next):\n",
    "        \n",
    "        batch_size = self.Z.shape[1]\n",
    "        \n",
    "        #compute and keep gradients\n",
    "        self.dA = np.dot(W_next.T, dZ_next)\n",
    "        self.dZ = self.dA * self.activation.derivative(self.Z)\n",
    "        \n",
    "        #regularization\n",
    "        l2_term = (self.l2_reg / batch_size) * self.W\n",
    "        \n",
    "        self.dW = np.dot(self.dZ, self.A_prev.T) * (1 / batch_size) + l2_term\n",
    "        self.db = np.sum(self.dZ, axis=1, keepdims=True) * (1 / batch_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4dd48984",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = Layer(3, activation=Sigmoid)\n",
    "\n",
    "\n",
    "X = np.array([[3, 4],\n",
    "              [0, 3],\n",
    "               [2, 4],\n",
    "               [0 , 0],\n",
    "                [3, 0]]).T\n",
    "\n",
    "y = np.array([[1, 0, 1, 0, 1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dbff54c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = Layer(n_units=3, activation = RELU)\n",
    "layer2 = Layer(1, Sigmoid)\n",
    "costf = BinaryCrossEntropy()\n",
    "\n",
    "layer1.initialize(2)\n",
    "layer2.initialize(3)\n",
    "\n",
    "\n",
    "a1 = layer1.forward_propogation(X)\n",
    "a2 = layer2.forward_propogation(a1)\n",
    "\n",
    "cost = costf.compute_cost(a2, y)\n",
    "dA = costf.derivative(a2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "154d51d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.04124473e+00,  1.74107941e+03, -1.00433171e+00,\n",
       "         2.00000000e+00, -6.67283823e+00]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a82e2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71158021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
